{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AGZnIIIblll4"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "class Vocab:\n",
        "\n",
        "    def __init__(self, tokens=None, reserved_tokens=None, min_freq=0):\n",
        "\n",
        "        if tokens is None:\n",
        "            tokens = []\n",
        "        if reserved_tokens is None:\n",
        "            reserved_tokens = []\n",
        "\n",
        "        counter = count_corpus(tokens)\n",
        "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
        "        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
        "        for token, freq in self._token_freqs:\n",
        "            if freq < min_freq:\n",
        "                break\n",
        "            if token not in self.token_to_idx:\n",
        "                self.idx_to_token.append(token)\n",
        "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        if not isinstance(tokens, (list, tuple)):\n",
        "            return self.token_to_idx.get(tokens, self.unk)\n",
        "        return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "    def to_tokens(self, indices):\n",
        "        if not isinstance(indices, (list, tuple)):\n",
        "            return self.idx_to_token[indices]\n",
        "        return [self.idx_to_token[index] for index in indices]\n",
        "\n",
        "    @property\n",
        "    def unk(self):\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def token_freqs(self):\n",
        "        return self._token_freqs\n",
        "\n",
        "def tokenize(lines, type_=\"char\", lower_case=True):\n",
        "\n",
        "    if lower_case:\n",
        "        lines = [line.lower() for line in lines]\n",
        "    if type_ == \"word\":\n",
        "        return [line.split() for line in lines]\n",
        "    elif type_ == \"char\":\n",
        "        return [list(line) for line in lines]\n",
        "    else:\n",
        "        print(\"unknown type, type should be in ['char', 'word']\")\n",
        "\n",
        "def count_corpus(lines):\n",
        "\n",
        "    token_list = [token for line in lines for token in line]\n",
        "    c = Counter(token_list)\n",
        "\n",
        "    return c\n",
        "\n",
        "def seq_padding(tokens, trim_length=100, fill_char='<unk>'):\n",
        "\n",
        "    tokens_trim = []\n",
        "    \n",
        "    for line in tokens:\n",
        "        if len(line) >= trim_length:\n",
        "            tokens_trim.append(line[:trim_length])\n",
        "        else:\n",
        "            fill_length = trim_length - len(line)\n",
        "            tokens_trim.append(line + [fill_char] * fill_length)\n",
        "        \n",
        "    return tokens_trim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWxvrqY8Yx9Y",
        "outputId": "a327323b-53e5-480c-c438-38e73f45e17b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import sys\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/')\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpTLRyowY8EJ",
        "outputId": "2880a839-8134-4df5-c5f1-2fbf6b76e710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Kaggle_FB3_ELL' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.1.0)\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/PANDASANG1231/Kaggle_FB3_ELL.git\n",
        "! pip install catboost\n",
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ObDpZyfWbLP-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/Kaggle_FB3_ELL/data/train.csv\")\n",
        "data_test = pd.read_csv(\"/content/Kaggle_FB3_ELL/data/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4TiTnPfFbj4A"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "\n",
        "en_stopwords = stopwords.words(\"english\")\n",
        "\n",
        "data_train, data_valid = train_test_split(data, test_size=int(0.1*data.shape[0]), random_state=2022)\n",
        "# data_train = data_train.sample(100)\n",
        "\n",
        "data_train[\"text_processed\"] = data_train[\"full_text\"] \\\n",
        "    .apply(lambda x: x.lower()) \\\n",
        "    .apply(lambda x: re.sub(r'\\W+', ' ', x)) \\\n",
        "    .apply(lambda row: \" \".join([word for word in row.split(\" \") if word not in en_stopwords]))\n",
        "\n",
        "data_valid[\"text_processed\"] = data_valid[\"full_text\"] \\\n",
        "    .apply(lambda x: x.lower()) \\\n",
        "    .apply(lambda x: re.sub(r'\\W+', ' ', x)) \\\n",
        "    .apply(lambda row: \" \".join([word for word in row.split(\" \") if word not in en_stopwords]))\n",
        "\n",
        "data_test[\"text_processed\"] = data_test[\"full_text\"] \\\n",
        "    .apply(lambda x: x.lower()) \\\n",
        "    .apply(lambda x: re.sub(r'\\W+', ' ', x)) \\\n",
        "    .apply(lambda row: \" \".join([word for word in row.split(\" \") if word not in en_stopwords]))\n",
        "\n",
        "\n",
        "X_train = data_train['text_processed'].values\n",
        "X_valid = data_valid['text_processed'].values\n",
        "X_test = data_test['text_processed'].values\n",
        "\n",
        "y_train = data_train[['cohesion','syntax','vocabulary','phraseology','grammar','conventions']].values\n",
        "y_valid = data_valid[['cohesion','syntax','vocabulary','phraseology','grammar','conventions']].values\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import utils\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "class FB3DataSet(utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, vocab, corpus, y=None, trim_length=200):\n",
        "\n",
        "        self.vocab = vocab\n",
        "        self.corpus = corpus\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.corpus)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        if self.y is None:\n",
        "            return torch.LongTensor(self.corpus[idx])\n",
        "        else:\n",
        "            return torch.LongTensor(self.corpus[idx]), torch.FloatTensor(self.y[idx])\n",
        "\n",
        "\n",
        "class FB3_LSTM_model(nn.Module):\n",
        "\n",
        "    def __init__(self, num_embeddings, embedding_dim, output_size, bidirectional,\n",
        "                 hidden_size=128, num_layers=2, time_len=200):\n",
        "\n",
        "        super(FB3_LSTM_model, self).__init__()\n",
        "\n",
        "        self.head = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim)\n",
        "\n",
        "        self.backbone = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, \\\n",
        "                                batch_first=True, num_layers=num_layers, \\\n",
        "                                bidirectional=bidirectional)\n",
        "        \n",
        "        middle_dim = time_len * hidden_size * (int(bidirectional) + 1)\n",
        "\n",
        "        self.tail = nn.Sequential(\n",
        "    \n",
        "                        nn.BatchNorm1d(num_features=middle_dim),\n",
        "                        nn.Linear(middle_dim, 128),\n",
        "                        nn.ReLU(),\n",
        "\n",
        "                        nn.BatchNorm1d(num_features=128),\n",
        "                        nn.Linear(128, output_size),\n",
        "\n",
        "                    )\n",
        "        \n",
        "    def forward(self, x, s=None):\n",
        "\n",
        "        x = self.head(x)\n",
        "\n",
        "        if s is None:\n",
        "            x, s = self.backbone(x.float())\n",
        "        else:\n",
        "            x, s = self.backbone(x.float(), s)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        y = self.tail(x)\n",
        "\n",
        "        return y, s\n",
        "\n"
      ],
      "metadata": {
        "id": "5KkwYPleCLLY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mcrmse(y_pred, y_true):\n",
        "\n",
        "    return (((y_pred - y_true) ** 2).mean(axis=1) ** 0.5).mean()\n",
        "\n",
        "\n",
        "def train_epoch(model, train_dataloader, valid_dataloader, loss, optimizer, scheduler, device):\n",
        "\n",
        "    state = None\n",
        "    eval_accu = [0, 0]\n",
        "\n",
        "    for batch_X, batch_y in tqdm(train_dataloader, total=len(train_dataloader)):    \n",
        "\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        model.train()\n",
        "\n",
        "        if state is None:\n",
        "            pass\n",
        "        elif not isinstance(state, list) and not isinstance(state, tuple):\n",
        "            state.detach_()\n",
        "        else:\n",
        "            for s in state:\n",
        "                s.detach_()\n",
        "\n",
        "        batch_y_pred, state = model(batch_X, state)\n",
        "\n",
        "        batch_loss = loss(batch_y_pred, batch_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            n = batch_X.shape[0] * batch_X.shape[1]\n",
        "            eval_accu = [sum(x) for x in zip(*[eval_accu, [n, batch_loss * n]])]\n",
        "\n",
        "    train_metrics = {\"train_loss\": eval_accu[1] / eval_accu[0]}\n",
        "\n",
        "    state = None\n",
        "    eval_accu = [0, 0]\n",
        "\n",
        "    for batch_X, batch_y in tqdm(valid_dataloader, total=len(valid_dataloader)):\n",
        "\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        batch_y_pred, state = model(batch_X, state)\n",
        "        batch_loss = loss(batch_y_pred, batch_y)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            n = batch_X.shape[0] * batch_X.shape[1]\n",
        "            eval_accu = [sum(x) for x in zip(*[eval_accu, [n, batch_loss * n]])]\n",
        "\n",
        "    valid_metrics = {\"valid_loss\": eval_accu[1] / eval_accu[0]}\n",
        "\n",
        "\n",
        "    return train_metrics, valid_metrics\n",
        "\n",
        "\n",
        "def train(model, \n",
        "          train_data_iter, \n",
        "          valid_data_iter, \n",
        "          epochs=50,\n",
        "          warmup_prop=0.1,\n",
        "          lr=1e-2,\n",
        "          device=torch.device(\"cuda\"),\n",
        "          ):\n",
        "\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    \n",
        "    num_training_steps = int(epochs * len(train_data_iter))\n",
        "    num_warmup_steps = int(warmup_prop * num_training_steps)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps, num_training_steps\n",
        "    )\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        train_metrics, valid_metrics = train_epoch(model, \n",
        "                                                   train_data_iter, \n",
        "                                                   valid_data_iter, \n",
        "                                                   mcrmse, \n",
        "                                                   optimizer, \n",
        "                                                   scheduler, \n",
        "                                                   device)\n",
        "        lr = scheduler.get_last_lr()[0]\n",
        "        print(f\"Epoch {epoch + 1:02d}/{epochs:02d} \\t lr={lr:.1e}\\t\")\n",
        "        print(train_metrics, valid_metrics)\n",
        "\n"
      ],
      "metadata": {
        "id": "NdlVgLNDMPdH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_len = 300\n",
        "\n",
        "# Preprocess data\n",
        "tokens_train = tokenize(X_train, type_=\"word\", lower_case=True)\n",
        "tokens_train = seq_padding(tokens_train, trim_length=time_len, fill_char='<unk>')\n",
        "vocab = Vocab(tokens_train, min_freq=0)\n",
        "corpus_train = [[vocab[token] for token in line] for line in tokens_train]\n",
        "\n",
        "tokens_valid = tokenize(X_valid, type_=\"word\", lower_case=True)\n",
        "tokens_valid = seq_padding(tokens_valid, trim_length=time_len, fill_char='<unk>')\n",
        "corpus_valid = [[vocab[token] for token in line] for line in tokens_valid]\n",
        "\n",
        "tokens_test = tokenize(X_test, type_=\"word\", lower_case=True)\n",
        "tokens_test = seq_padding(tokens_test, trim_length=time_len, fill_char='<unk>')\n",
        "corpus_test = [[vocab[token] for token in line] for line in tokens_test]\n",
        "\n",
        "\n",
        "## Pytorch dataset\n",
        "fb_train_dataset = FB3DataSet(vocab, corpus_train, y_train, trim_length=time_len)\n",
        "fb_valid_dataset = FB3DataSet(vocab, corpus_valid, y_valid, trim_length=time_len)\n",
        "fb_test_dataset = FB3DataSet(vocab, corpus_test, None, trim_length=time_len)\n",
        "\n",
        "\n",
        "## Pytorch dataloader\n",
        "train_dataloader = utils.data.DataLoader(dataset=fb_train_dataset, batch_size=64, drop_last=True,\n",
        "                                         num_workers=4, pin_memory=False, shuffle=True)\n",
        "valid_dataloader = utils.data.DataLoader(dataset=fb_valid_dataset, batch_size=64, drop_last=True,\n",
        "                                         num_workers=4, pin_memory=False, shuffle=False)\n",
        "test_dataloader = utils.data.DataLoader(dataset=fb_test_dataset, batch_size=len(fb_test_dataset),\n",
        "                                        drop_last=True, num_workers=4, pin_memory=False, shuffle=False)\n",
        "\n",
        "## Model\n",
        "model = FB3_LSTM_model(num_embeddings=len(vocab.token_to_idx), embedding_dim=500, bidirectional=True,\\\n",
        "                       output_size=6, hidden_size=600, num_layers=1, time_len=time_len)\n",
        "\n",
        "## Train\n",
        "train(model, train_dataloader, valid_dataloader, lr=0.05, epochs=5, device=torch.device(\"cuda\"))\n",
        "# train(model, train_dataloader, valid_dataloader, lr=0.02, epochs=10, device=torch.device(\"cuda\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NzpXSkmPrYc",
        "outputId": "2e6bf570-0b29-4be9-d208-932530aae883"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:12<00:00,  4.29it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00,  9.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/05 \t lr=4.4e-02\t\n",
            "{'train_loss': tensor(2.9721, device='cuda:0')} {'valid_loss': tensor(2.5814, device='cuda:0')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:13<00:00,  4.23it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00,  8.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02/05 \t lr=3.3e-02\t\n",
            "{'train_loss': tensor(2.0809, device='cuda:0')} {'valid_loss': tensor(2.9385, device='cuda:0')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:13<00:00,  4.15it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00,  8.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03/05 \t lr=2.2e-02\t\n",
            "{'train_loss': tensor(0.8054, device='cuda:0')} {'valid_loss': tensor(0.5962, device='cuda:0')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:13<00:00,  4.07it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00,  8.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04/05 \t lr=1.1e-02\t\n",
            "{'train_loss': tensor(0.4575, device='cuda:0')} {'valid_loss': tensor(0.6030, device='cuda:0')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:13<00:00,  4.02it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05/05 \t lr=0.0e+00\t\n",
            "{'train_loss': tensor(0.3098, device='cuda:0')} {'valid_loss': tensor(0.5725, device='cuda:0')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in valid_dataloader:\n",
        "\n",
        "    X = X.to(torch.device(\"cuda\"))\n",
        "\n",
        "    pred = model(X)[0].to(torch.device(\"cpu\"))\n",
        "\n",
        "    print(y, pred)\n",
        "\n",
        "for X in test_dataloader:\n",
        "\n",
        "    X = X.to(torch.device(\"cuda\"))\n",
        "\n",
        "    pred = model(X)[0].to(torch.device(\"cpu\"))\n",
        "\n",
        "    print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEb1jPFUuJk6",
        "outputId": "feb7fa3f-574b-40c2-ebef-c8d31eb71b94"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.5000, 2.5000, 3.0000, 3.0000, 3.5000, 3.0000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.5000, 4.0000, 3.5000],\n",
            "        [3.5000, 3.0000, 3.0000, 2.5000, 3.0000, 3.0000],\n",
            "        [3.5000, 2.5000, 3.0000, 3.0000, 2.5000, 3.5000],\n",
            "        [2.5000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [3.5000, 3.0000, 3.0000, 2.5000, 2.5000, 3.5000],\n",
            "        [2.5000, 2.0000, 3.0000, 3.0000, 2.5000, 2.5000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.5000, 4.0000, 4.0000],\n",
            "        [3.0000, 3.0000, 2.5000, 3.0000, 2.0000, 3.0000],\n",
            "        [2.0000, 1.5000, 2.0000, 2.0000, 2.0000, 1.0000],\n",
            "        [3.5000, 4.0000, 4.0000, 4.0000, 3.5000, 4.5000],\n",
            "        [2.5000, 2.0000, 2.5000, 3.0000, 2.5000, 2.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 2.5000, 2.5000],\n",
            "        [4.0000, 4.0000, 3.5000, 4.0000, 3.0000, 3.5000],\n",
            "        [2.5000, 2.0000, 2.5000, 2.0000, 2.0000, 2.0000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.0000, 3.0000, 4.0000],\n",
            "        [3.5000, 3.5000, 3.0000, 4.0000, 3.0000, 3.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [3.0000, 3.5000, 4.0000, 3.5000, 3.5000, 3.0000],\n",
            "        [3.5000, 4.0000, 3.5000, 3.5000, 4.0000, 4.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 2.5000, 2.0000, 3.5000],\n",
            "        [3.0000, 2.5000, 2.5000, 2.5000, 2.5000, 3.0000],\n",
            "        [3.5000, 3.5000, 2.5000, 3.0000, 3.0000, 3.5000],\n",
            "        [2.5000, 3.0000, 2.5000, 2.0000, 2.0000, 2.0000],\n",
            "        [2.5000, 2.5000, 2.5000, 2.0000, 2.0000, 2.5000],\n",
            "        [4.0000, 3.5000, 4.0000, 4.0000, 3.0000, 4.0000],\n",
            "        [4.0000, 3.0000, 4.0000, 3.0000, 3.5000, 3.0000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.5000, 3.0000, 3.0000],\n",
            "        [2.5000, 2.5000, 2.5000, 2.0000, 2.5000, 2.5000],\n",
            "        [3.5000, 2.5000, 3.0000, 3.0000, 2.0000, 2.5000],\n",
            "        [3.0000, 2.5000, 3.0000, 3.0000, 2.0000, 2.5000],\n",
            "        [3.5000, 3.5000, 3.0000, 3.5000, 2.5000, 3.0000],\n",
            "        [3.0000, 2.5000, 2.5000, 2.0000, 2.5000, 3.0000],\n",
            "        [3.5000, 4.0000, 3.5000, 4.0000, 4.0000, 4.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 2.5000, 3.0000],\n",
            "        [3.5000, 3.5000, 4.0000, 4.0000, 3.5000, 3.5000],\n",
            "        [2.0000, 3.0000, 2.5000, 2.5000, 2.0000, 2.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [2.5000, 3.0000, 3.0000, 2.0000, 2.5000, 3.0000],\n",
            "        [4.0000, 3.0000, 4.0000, 3.5000, 3.0000, 3.0000],\n",
            "        [4.5000, 3.5000, 3.5000, 4.0000, 5.0000, 4.0000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.5000, 3.0000, 3.5000],\n",
            "        [4.0000, 3.5000, 3.5000, 3.5000, 3.0000, 4.0000],\n",
            "        [3.0000, 2.5000, 3.0000, 3.0000, 3.0000, 2.5000],\n",
            "        [2.5000, 2.5000, 3.0000, 2.5000, 2.0000, 2.5000],\n",
            "        [4.0000, 4.0000, 4.0000, 3.5000, 3.0000, 3.0000],\n",
            "        [3.5000, 2.5000, 3.5000, 3.0000, 3.0000, 3.5000],\n",
            "        [3.0000, 2.0000, 3.0000, 3.0000, 2.5000, 2.5000],\n",
            "        [5.0000, 4.0000, 4.0000, 4.5000, 5.0000, 4.5000],\n",
            "        [3.0000, 3.5000, 3.0000, 3.0000, 3.0000, 3.5000],\n",
            "        [3.0000, 2.5000, 3.5000, 3.0000, 3.0000, 3.5000],\n",
            "        [2.0000, 2.0000, 2.5000, 3.0000, 2.5000, 2.5000],\n",
            "        [4.0000, 4.0000, 4.5000, 4.0000, 3.5000, 4.0000],\n",
            "        [2.0000, 3.0000, 2.5000, 2.0000, 2.5000, 2.5000],\n",
            "        [2.5000, 3.0000, 3.0000, 3.0000, 2.5000, 2.0000],\n",
            "        [4.0000, 3.5000, 4.0000, 3.0000, 4.0000, 4.0000],\n",
            "        [2.5000, 2.0000, 3.0000, 2.5000, 3.0000, 2.0000],\n",
            "        [2.5000, 3.0000, 2.5000, 2.0000, 2.0000, 2.0000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.5000, 3.0000, 2.5000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.5000, 3.0000, 3.5000],\n",
            "        [4.0000, 3.5000, 4.0000, 4.0000, 4.0000, 3.0000],\n",
            "        [3.0000, 2.5000, 3.0000, 3.5000, 2.5000, 3.0000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.5000, 3.5000, 3.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 2.5000, 3.0000]]) tensor([[2.6029, 2.5872, 2.8461, 2.7830, 2.7893, 2.7292],\n",
            "        [2.8602, 2.6499, 2.8050, 2.8996, 2.7342, 2.7663],\n",
            "        [2.8352, 2.7895, 3.0014, 2.8135, 3.0084, 2.9292],\n",
            "        [3.1998, 3.1289, 3.1337, 3.2625, 3.0806, 3.2647],\n",
            "        [2.5322, 2.6402, 2.9846, 3.0280, 2.9094, 2.7904],\n",
            "        [3.4211, 3.1963, 3.4619, 3.4991, 3.2815, 3.3511],\n",
            "        [2.9872, 3.0563, 3.3183, 3.3484, 2.9487, 3.1134],\n",
            "        [3.1317, 3.1532, 3.4379, 3.1085, 3.1130, 3.2703],\n",
            "        [3.3730, 3.0495, 3.3608, 3.3752, 3.2521, 3.0564],\n",
            "        [2.7135, 2.6675, 2.9506, 2.5988, 2.6000, 2.7765],\n",
            "        [2.9382, 2.9669, 3.0663, 2.8077, 3.3306, 3.1025],\n",
            "        [2.5723, 2.4779, 2.6437, 2.6127, 2.6374, 2.4555],\n",
            "        [2.5842, 2.6540, 2.7070, 2.8565, 2.8846, 2.7751],\n",
            "        [3.3951, 3.1308, 3.4714, 3.3288, 3.1512, 3.2333],\n",
            "        [2.9279, 2.7857, 3.1601, 3.0491, 2.8925, 2.9603],\n",
            "        [3.5438, 3.2649, 3.3027, 3.3082, 3.1385, 3.2374],\n",
            "        [3.0054, 2.9243, 3.0422, 2.8371, 2.9310, 2.8546],\n",
            "        [3.1346, 2.7319, 3.1670, 3.0577, 2.7554, 3.0239],\n",
            "        [3.2671, 3.1032, 3.3515, 3.5418, 3.1349, 3.1946],\n",
            "        [3.3551, 3.1884, 3.1618, 3.1255, 3.0310, 3.2935],\n",
            "        [2.7746, 2.8065, 2.8583, 2.9242, 2.4916, 2.7831],\n",
            "        [3.2654, 3.0056, 3.1640, 3.0640, 2.8608, 3.0801],\n",
            "        [2.8848, 2.7807, 2.9530, 2.8305, 2.8679, 2.8193],\n",
            "        [2.7449, 2.4996, 2.6445, 2.5517, 2.5061, 2.5298],\n",
            "        [2.5080, 2.3955, 2.6367, 2.4857, 2.2600, 2.3571],\n",
            "        [2.9926, 2.9562, 3.1978, 3.3048, 3.0619, 3.0947],\n",
            "        [3.0154, 2.9426, 2.9238, 2.8621, 2.6825, 2.7386],\n",
            "        [3.0654, 3.1252, 3.3793, 3.3462, 3.3358, 3.1881],\n",
            "        [2.9060, 2.4958, 2.8692, 2.7359, 2.4558, 2.8134],\n",
            "        [3.1172, 2.8600, 3.2314, 3.0651, 2.8298, 2.9529],\n",
            "        [2.9503, 2.8440, 3.2468, 3.2114, 3.1900, 2.7171],\n",
            "        [3.3163, 3.1680, 3.3307, 3.0746, 3.0345, 2.8987],\n",
            "        [2.8942, 2.7980, 3.0197, 2.7653, 2.8928, 2.7524],\n",
            "        [3.1804, 3.2562, 3.2029, 3.4496, 3.3079, 3.3459],\n",
            "        [3.2080, 3.1765, 3.4639, 3.2908, 3.0119, 3.2860],\n",
            "        [3.1060, 2.8050, 3.2976, 3.0095, 2.7748, 2.9940],\n",
            "        [2.5162, 2.1840, 2.6836, 2.6285, 2.1761, 2.6242],\n",
            "        [3.5430, 3.2134, 3.4012, 3.4910, 3.3281, 3.3110],\n",
            "        [3.0593, 3.0343, 3.1964, 3.1306, 2.9615, 3.1182],\n",
            "        [3.3693, 3.3490, 3.5521, 3.5820, 3.1289, 3.4179],\n",
            "        [3.3717, 3.2143, 3.4085, 3.3438, 3.3149, 3.2908],\n",
            "        [3.5048, 3.1599, 3.4335, 3.2880, 3.1782, 3.2606],\n",
            "        [3.5615, 3.4586, 3.6045, 3.6588, 3.0372, 3.3627],\n",
            "        [3.3081, 2.7915, 3.2246, 3.1301, 2.7872, 2.8591],\n",
            "        [3.2224, 3.0961, 3.3887, 3.2991, 2.9821, 3.1310],\n",
            "        [3.4019, 3.3102, 3.6104, 3.5435, 3.3019, 3.2154],\n",
            "        [3.0503, 3.2057, 3.3190, 3.0385, 2.7772, 3.0708],\n",
            "        [3.2435, 2.9712, 3.4480, 3.3477, 2.9267, 3.2449],\n",
            "        [3.6713, 3.4961, 3.5364, 3.6087, 3.2621, 3.5433],\n",
            "        [2.6821, 2.6650, 2.8288, 2.8133, 2.9958, 2.6510],\n",
            "        [2.7866, 2.6851, 2.7873, 2.9919, 2.6911, 2.9116],\n",
            "        [2.6347, 2.5095, 2.7170, 2.5514, 2.5338, 2.4991],\n",
            "        [2.8801, 3.1693, 3.4747, 3.2812, 3.5377, 3.1487],\n",
            "        [3.2512, 3.1477, 3.3591, 3.0956, 2.9464, 2.9523],\n",
            "        [2.6588, 2.5272, 2.7643, 2.7498, 2.5257, 2.8054],\n",
            "        [2.7819, 2.7881, 2.8873, 2.7419, 2.8994, 2.7546],\n",
            "        [2.6698, 2.8883, 2.7879, 2.7271, 2.6820, 2.5578],\n",
            "        [3.2103, 3.0778, 3.0974, 3.0204, 2.8411, 3.1623],\n",
            "        [3.2343, 3.2796, 3.4602, 3.2108, 3.2160, 3.0579],\n",
            "        [3.3196, 3.2628, 3.4040, 3.4290, 3.2392, 3.3658],\n",
            "        [3.2261, 3.2216, 3.2366, 3.3074, 3.1125, 3.2620],\n",
            "        [3.4726, 3.3331, 3.4772, 3.5833, 3.3613, 3.3943],\n",
            "        [3.0489, 3.0435, 3.0248, 3.0632, 2.7983, 3.1228],\n",
            "        [3.5076, 3.3685, 3.6829, 3.5266, 3.5264, 3.4911]],\n",
            "       grad_fn=<ToCopyBackward0>)\n",
            "tensor([[3.0000, 4.0000, 3.0000, 3.5000, 3.5000, 3.0000],\n",
            "        [1.5000, 1.5000, 1.5000, 1.0000, 1.0000, 1.0000],\n",
            "        [3.5000, 4.0000, 3.5000, 3.5000, 3.5000, 4.0000],\n",
            "        [4.0000, 4.5000, 4.5000, 4.5000, 4.0000, 3.5000],\n",
            "        [3.0000, 4.0000, 4.0000, 4.0000, 4.0000, 3.0000],\n",
            "        [3.5000, 3.5000, 4.5000, 3.5000, 3.5000, 3.5000],\n",
            "        [3.0000, 3.0000, 3.5000, 4.0000, 4.0000, 3.5000],\n",
            "        [3.0000, 3.5000, 3.0000, 3.0000, 3.5000, 3.5000],\n",
            "        [2.5000, 3.0000, 3.5000, 3.0000, 3.5000, 3.0000],\n",
            "        [3.0000, 2.5000, 3.0000, 3.0000, 2.5000, 2.5000],\n",
            "        [3.5000, 3.0000, 3.0000, 3.0000, 2.5000, 3.0000],\n",
            "        [2.0000, 2.5000, 2.5000, 2.5000, 2.0000, 2.5000],\n",
            "        [3.5000, 2.5000, 3.0000, 3.5000, 2.5000, 3.0000],\n",
            "        [3.0000, 3.0000, 3.5000, 3.0000, 3.5000, 3.5000],\n",
            "        [3.5000, 3.5000, 4.0000, 4.0000, 3.5000, 3.5000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.5000, 3.5000, 4.0000],\n",
            "        [2.0000, 2.0000, 3.0000, 3.0000, 2.5000, 2.5000],\n",
            "        [2.0000, 2.5000, 3.0000, 3.0000, 2.5000, 2.0000],\n",
            "        [3.0000, 2.5000, 2.5000, 2.5000, 2.5000, 2.0000],\n",
            "        [4.0000, 3.0000, 3.0000, 3.0000, 3.0000, 4.0000],\n",
            "        [4.0000, 4.0000, 4.5000, 4.0000, 3.5000, 4.0000],\n",
            "        [3.5000, 2.5000, 3.5000, 3.5000, 3.0000, 3.5000],\n",
            "        [4.0000, 3.0000, 3.0000, 2.5000, 3.0000, 3.0000],\n",
            "        [4.0000, 3.0000, 3.5000, 3.5000, 3.5000, 3.5000],\n",
            "        [5.0000, 4.5000, 5.0000, 4.5000, 4.5000, 4.0000],\n",
            "        [3.0000, 3.0000, 3.5000, 3.5000, 3.0000, 2.5000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [3.5000, 3.0000, 3.0000, 2.5000, 3.0000, 3.5000],\n",
            "        [4.0000, 3.5000, 4.0000, 3.5000, 3.5000, 4.5000],\n",
            "        [3.5000, 2.5000, 3.5000, 3.0000, 3.0000, 3.0000],\n",
            "        [3.5000, 3.0000, 3.0000, 3.0000, 2.5000, 3.5000],\n",
            "        [4.0000, 4.0000, 4.0000, 3.5000, 4.0000, 3.5000],\n",
            "        [2.0000, 2.0000, 2.5000, 2.0000, 2.0000, 2.0000],\n",
            "        [4.0000, 3.0000, 4.0000, 3.5000, 3.5000, 4.0000],\n",
            "        [4.0000, 3.5000, 3.0000, 3.0000, 4.0000, 4.0000],\n",
            "        [4.5000, 4.5000, 3.5000, 4.5000, 3.0000, 3.5000],\n",
            "        [3.0000, 3.5000, 3.5000, 4.0000, 3.5000, 3.0000],\n",
            "        [3.5000, 4.0000, 3.5000, 3.5000, 4.0000, 3.0000],\n",
            "        [2.5000, 2.0000, 2.5000, 3.0000, 3.0000, 2.0000],\n",
            "        [3.0000, 2.5000, 3.0000, 3.0000, 2.0000, 3.0000],\n",
            "        [4.0000, 3.5000, 4.0000, 3.5000, 3.5000, 3.0000],\n",
            "        [4.5000, 4.5000, 4.5000, 4.0000, 4.0000, 4.5000],\n",
            "        [4.5000, 4.0000, 4.5000, 4.0000, 4.0000, 4.0000],\n",
            "        [2.0000, 2.0000, 2.5000, 3.0000, 2.0000, 2.0000],\n",
            "        [4.0000, 3.5000, 3.0000, 3.5000, 3.5000, 3.5000],\n",
            "        [2.5000, 2.5000, 2.5000, 2.5000, 2.0000, 2.5000],\n",
            "        [3.0000, 3.0000, 4.0000, 3.5000, 3.0000, 3.0000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.5000, 3.5000, 3.0000],\n",
            "        [3.5000, 3.0000, 3.0000, 3.5000, 3.5000, 2.5000],\n",
            "        [2.5000, 2.0000, 3.0000, 2.5000, 2.0000, 2.5000],\n",
            "        [4.5000, 4.0000, 4.0000, 4.0000, 3.5000, 3.0000],\n",
            "        [2.5000, 3.0000, 2.5000, 3.0000, 2.5000, 2.5000],\n",
            "        [4.5000, 4.5000, 5.0000, 4.5000, 4.5000, 4.5000],\n",
            "        [2.5000, 2.0000, 3.0000, 2.5000, 2.5000, 2.5000],\n",
            "        [2.5000, 2.0000, 3.0000, 2.5000, 2.5000, 2.0000],\n",
            "        [3.5000, 3.0000, 3.0000, 4.0000, 4.0000, 3.5000],\n",
            "        [4.0000, 4.0000, 4.0000, 4.0000, 3.5000, 3.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.5000],\n",
            "        [3.0000, 3.0000, 3.5000, 3.5000, 4.0000, 3.5000],\n",
            "        [2.5000, 2.5000, 3.5000, 3.5000, 3.0000, 3.5000],\n",
            "        [3.5000, 4.0000, 3.5000, 3.0000, 3.0000, 4.0000],\n",
            "        [3.5000, 2.5000, 2.0000, 2.5000, 2.5000, 3.0000],\n",
            "        [3.0000, 3.0000, 3.5000, 3.0000, 2.5000, 3.0000],\n",
            "        [3.0000, 3.0000, 2.5000, 2.5000, 3.5000, 3.5000]]) tensor([[2.4736, 2.3956, 2.6114, 2.6407, 2.5535, 2.6166],\n",
            "        [3.0132, 3.1548, 3.2402, 3.2454, 3.0940, 3.2429],\n",
            "        [2.9935, 2.9402, 3.3203, 3.0299, 3.0767, 3.0144],\n",
            "        [3.3147, 3.2408, 3.4936, 3.3476, 3.4758, 3.2203],\n",
            "        [3.1963, 3.3415, 3.3386, 3.2069, 3.2978, 3.4170],\n",
            "        [3.2603, 3.1703, 3.5146, 3.4271, 3.0580, 3.0456],\n",
            "        [3.3164, 3.3053, 3.2122, 3.2904, 3.1750, 3.3271],\n",
            "        [2.8332, 2.8538, 2.9919, 3.0576, 3.1386, 2.9986],\n",
            "        [2.8046, 2.6107, 2.8261, 2.8068, 2.6341, 2.7415],\n",
            "        [2.6211, 2.5493, 2.8447, 2.6320, 2.8755, 2.5087],\n",
            "        [3.4793, 3.3229, 3.3828, 3.3996, 3.1879, 3.2356],\n",
            "        [3.2478, 2.9891, 3.3244, 3.3503, 2.9712, 3.0301],\n",
            "        [3.3757, 3.1897, 3.4046, 3.3520, 3.1122, 3.0802],\n",
            "        [2.9367, 2.9377, 3.1025, 2.8446, 3.0150, 2.9329],\n",
            "        [3.3401, 3.1535, 3.3492, 3.3052, 2.9583, 3.2945],\n",
            "        [3.1948, 3.2947, 3.4341, 3.1756, 3.0588, 3.1086],\n",
            "        [3.1376, 2.9416, 3.2916, 3.4499, 3.2371, 3.2129],\n",
            "        [2.8292, 3.0703, 2.9449, 2.7940, 2.5621, 2.9364],\n",
            "        [3.2815, 3.3067, 3.2541, 3.3571, 2.9024, 3.1606],\n",
            "        [2.9022, 2.8796, 3.2724, 3.1003, 2.9314, 3.2317],\n",
            "        [2.8958, 2.9321, 3.3819, 3.2209, 2.7909, 3.0094],\n",
            "        [3.3634, 3.0456, 3.1240, 3.0123, 3.0232, 3.1998],\n",
            "        [2.8992, 2.9419, 3.1815, 2.8530, 2.8543, 2.9131],\n",
            "        [3.4689, 3.1660, 3.5353, 3.4356, 3.1589, 3.2053],\n",
            "        [3.4393, 3.3373, 3.5583, 3.4132, 3.0758, 3.2923],\n",
            "        [2.9347, 2.8359, 3.4114, 3.1530, 2.8840, 2.8772],\n",
            "        [2.9433, 2.9762, 3.0525, 3.1301, 2.8035, 3.0956],\n",
            "        [3.2511, 3.1381, 3.1542, 3.2000, 2.9470, 3.0821],\n",
            "        [3.4478, 3.5432, 3.8656, 3.6097, 3.3520, 3.5432],\n",
            "        [2.9712, 2.8676, 3.2913, 3.1281, 2.7400, 2.7870],\n",
            "        [3.0300, 2.9282, 2.9970, 2.9073, 3.0070, 2.8156],\n",
            "        [3.1755, 2.9706, 3.1101, 3.2615, 3.1836, 3.0981],\n",
            "        [2.6663, 2.7282, 2.8441, 2.6311, 2.6496, 2.9083],\n",
            "        [3.0480, 3.0257, 3.4011, 3.1274, 3.1496, 3.1567],\n",
            "        [3.6118, 3.4062, 3.6642, 3.3440, 3.3474, 3.5817],\n",
            "        [3.3792, 3.3618, 3.6369, 3.6155, 3.1848, 3.4925],\n",
            "        [2.6340, 2.8132, 2.9714, 2.7907, 2.8430, 2.7849],\n",
            "        [3.4246, 3.4511, 3.4367, 3.5450, 3.5753, 3.5243],\n",
            "        [2.9373, 3.2774, 3.2964, 3.2314, 3.0928, 3.2098],\n",
            "        [3.0353, 2.9809, 3.0343, 3.1109, 2.7339, 3.0367],\n",
            "        [3.1248, 3.0234, 3.4318, 3.2314, 2.9829, 3.1357],\n",
            "        [3.9330, 3.5661, 3.7934, 3.6952, 3.4405, 3.5343],\n",
            "        [3.2471, 3.2872, 3.7050, 3.4935, 3.0091, 3.1858],\n",
            "        [2.6368, 2.7896, 2.8237, 2.6837, 2.6751, 2.7036],\n",
            "        [3.3180, 3.0620, 3.4995, 3.3723, 2.9960, 3.1496],\n",
            "        [3.0384, 2.8213, 3.4441, 3.2153, 2.7700, 3.1121],\n",
            "        [3.3766, 3.2259, 3.5105, 3.4305, 3.1406, 3.1692],\n",
            "        [2.9258, 3.0597, 3.1029, 3.0867, 2.9583, 3.0852],\n",
            "        [3.0866, 3.2378, 3.0021, 2.9899, 2.9768, 3.0233],\n",
            "        [2.1067, 2.0880, 2.4348, 2.0146, 2.2026, 2.1948],\n",
            "        [3.3050, 3.4483, 3.4610, 3.4415, 3.1649, 3.4529],\n",
            "        [3.2020, 3.1349, 3.1998, 3.3593, 2.9745, 3.1039],\n",
            "        [3.3047, 3.5543, 3.6064, 3.5499, 3.5241, 3.4929],\n",
            "        [2.7968, 2.9327, 2.9314, 3.0126, 2.8335, 2.8378],\n",
            "        [2.9902, 2.9297, 3.1897, 3.0748, 2.6822, 2.8303],\n",
            "        [2.9620, 2.9632, 2.9781, 2.9596, 2.9347, 2.7936],\n",
            "        [3.4612, 3.1391, 3.4058, 3.4217, 3.0663, 3.2392],\n",
            "        [3.3776, 3.2608, 3.4071, 3.3840, 3.1603, 3.2240],\n",
            "        [2.6179, 2.5736, 2.8747, 2.8471, 2.4719, 2.8865],\n",
            "        [3.0970, 3.0474, 3.1651, 3.2714, 3.0726, 3.1889],\n",
            "        [3.3549, 3.0836, 3.3836, 3.2290, 3.1272, 3.1624],\n",
            "        [2.8277, 3.1644, 3.0350, 3.0866, 3.0713, 3.0352],\n",
            "        [3.4229, 3.2287, 3.4040, 3.2447, 3.0947, 3.2383],\n",
            "        [2.9657, 2.9534, 3.0129, 2.8885, 3.1163, 3.0510]],\n",
            "       grad_fn=<ToCopyBackward0>)\n",
            "tensor([[2.0000, 2.0000, 3.0000, 2.0000, 2.0000, 2.0000],\n",
            "        [3.5000, 3.5000, 4.0000, 4.0000, 3.5000, 3.0000],\n",
            "        [5.0000, 4.0000, 5.0000, 4.0000, 4.0000, 4.5000],\n",
            "        [2.5000, 2.5000, 3.0000, 3.0000, 2.5000, 3.0000],\n",
            "        [2.0000, 2.5000, 3.5000, 3.0000, 3.0000, 3.0000],\n",
            "        [2.0000, 3.0000, 2.5000, 3.0000, 2.5000, 3.0000],\n",
            "        [2.5000, 2.0000, 2.5000, 2.5000, 2.5000, 2.0000],\n",
            "        [4.0000, 3.0000, 3.5000, 2.5000, 3.0000, 3.5000],\n",
            "        [2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.5000],\n",
            "        [2.0000, 2.5000, 2.5000, 2.5000, 2.5000, 2.5000],\n",
            "        [2.5000, 3.0000, 3.0000, 2.5000, 2.5000, 2.5000],\n",
            "        [3.0000, 3.0000, 3.5000, 3.0000, 2.5000, 3.0000],\n",
            "        [5.0000, 5.0000, 4.5000, 5.0000, 5.0000, 4.5000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.5000, 3.0000, 3.0000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.0000, 3.0000, 3.5000],\n",
            "        [3.0000, 2.5000, 3.0000, 2.5000, 2.0000, 2.0000],\n",
            "        [2.5000, 2.5000, 3.0000, 3.0000, 2.0000, 2.5000],\n",
            "        [2.0000, 2.5000, 2.5000, 3.0000, 2.5000, 2.5000],\n",
            "        [1.5000, 2.0000, 2.0000, 2.0000, 2.0000, 2.5000],\n",
            "        [3.5000, 4.0000, 4.0000, 3.0000, 4.0000, 4.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 2.5000, 2.5000],\n",
            "        [3.5000, 3.0000, 3.5000, 2.5000, 3.0000, 3.5000],\n",
            "        [4.0000, 3.5000, 3.0000, 3.5000, 3.5000, 3.5000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.5000, 4.0000, 3.0000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 4.0000],\n",
            "        [4.5000, 4.0000, 5.0000, 4.5000, 4.5000, 4.5000],\n",
            "        [3.5000, 3.0000, 3.0000, 3.0000, 2.5000, 3.0000],\n",
            "        [3.5000, 3.0000, 3.5000, 4.0000, 3.5000, 3.0000],\n",
            "        [3.5000, 4.0000, 3.5000, 4.0000, 4.0000, 4.0000],\n",
            "        [3.0000, 3.5000, 4.0000, 4.0000, 3.5000, 3.5000],\n",
            "        [3.5000, 3.5000, 3.0000, 3.0000, 3.0000, 2.0000],\n",
            "        [3.0000, 2.5000, 3.0000, 3.0000, 2.5000, 3.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [4.0000, 3.0000, 3.5000, 3.5000, 3.5000, 4.0000],\n",
            "        [2.5000, 3.0000, 3.0000, 2.5000, 2.5000, 3.0000],\n",
            "        [2.0000, 3.0000, 3.0000, 3.0000, 3.0000, 2.5000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.5000, 3.5000, 3.0000],\n",
            "        [4.5000, 4.0000, 4.0000, 4.0000, 4.5000, 4.0000],\n",
            "        [3.5000, 3.5000, 3.5000, 4.0000, 3.5000, 3.0000],\n",
            "        [4.0000, 3.5000, 3.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [4.0000, 3.5000, 4.0000, 3.0000, 3.5000, 4.0000],\n",
            "        [4.5000, 4.5000, 4.5000, 4.5000, 4.5000, 4.5000],\n",
            "        [2.5000, 2.0000, 3.0000, 2.0000, 2.0000, 3.0000],\n",
            "        [3.0000, 2.5000, 3.0000, 2.0000, 3.0000, 2.0000],\n",
            "        [4.5000, 4.5000, 4.5000, 4.0000, 4.0000, 4.5000],\n",
            "        [3.0000, 3.0000, 3.0000, 4.0000, 2.5000, 3.0000],\n",
            "        [3.0000, 2.5000, 2.5000, 3.0000, 3.0000, 2.0000],\n",
            "        [4.0000, 3.0000, 3.0000, 3.0000, 3.5000, 4.0000],\n",
            "        [4.0000, 3.5000, 3.5000, 3.5000, 4.0000, 4.0000],\n",
            "        [2.0000, 2.0000, 3.0000, 2.0000, 2.0000, 2.0000],\n",
            "        [2.0000, 2.0000, 3.0000, 3.0000, 3.0000, 2.0000],\n",
            "        [2.5000, 2.5000, 2.5000, 2.0000, 2.0000, 2.0000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.5000, 2.5000, 3.5000],\n",
            "        [3.0000, 3.5000, 4.0000, 4.0000, 4.0000, 4.0000],\n",
            "        [3.5000, 3.0000, 3.0000, 3.5000, 4.0000, 4.0000],\n",
            "        [3.0000, 2.5000, 3.0000, 2.5000, 3.0000, 3.0000],\n",
            "        [3.0000, 3.5000, 3.5000, 4.0000, 3.5000, 3.0000],\n",
            "        [3.0000, 2.0000, 3.0000, 2.5000, 2.0000, 3.0000],\n",
            "        [2.5000, 2.5000, 3.0000, 3.0000, 2.5000, 2.0000],\n",
            "        [2.5000, 2.5000, 2.5000, 2.5000, 2.5000, 2.0000],\n",
            "        [2.5000, 3.0000, 3.0000, 2.5000, 3.0000, 2.5000],\n",
            "        [3.0000, 2.5000, 2.5000, 3.0000, 3.5000, 3.5000],\n",
            "        [4.0000, 4.0000, 4.5000, 4.0000, 4.5000, 4.5000],\n",
            "        [3.0000, 2.5000, 4.0000, 3.0000, 3.5000, 4.0000]]) tensor([[2.6894, 2.7743, 2.9756, 2.9974, 2.7649, 2.6781],\n",
            "        [3.4015, 3.2082, 3.4789, 3.4053, 2.9564, 3.2395],\n",
            "        [3.5256, 3.4171, 3.7728, 3.5313, 3.1126, 3.3549],\n",
            "        [3.3430, 3.2684, 3.3938, 3.3660, 3.2714, 3.4913],\n",
            "        [2.8463, 2.8708, 3.0238, 2.8779, 2.9531, 2.8838],\n",
            "        [3.2579, 3.3275, 3.3512, 3.3885, 3.1777, 3.3373],\n",
            "        [3.1433, 2.8073, 3.2308, 3.3427, 3.3293, 3.1974],\n",
            "        [3.3428, 3.0217, 3.1442, 2.9729, 2.7847, 2.8319],\n",
            "        [3.0323, 3.0474, 3.3174, 3.3264, 3.1344, 3.3830],\n",
            "        [3.3395, 3.2458, 3.2969, 3.2489, 2.7709, 3.1477],\n",
            "        [3.4879, 3.2674, 3.4113, 3.3533, 3.0319, 3.2325],\n",
            "        [3.2618, 3.3273, 3.7877, 3.6732, 3.4300, 3.3744],\n",
            "        [3.5948, 3.3601, 3.5888, 3.5296, 3.2947, 3.3589],\n",
            "        [3.3925, 2.9574, 3.4178, 3.3159, 3.2545, 3.1476],\n",
            "        [3.5209, 3.2304, 3.4955, 3.4142, 3.2522, 3.1927],\n",
            "        [2.8327, 2.5790, 2.9854, 3.0720, 2.4609, 2.7820],\n",
            "        [3.0546, 2.8872, 3.1450, 3.0454, 3.0718, 3.0875],\n",
            "        [2.8554, 2.7736, 3.1446, 2.9795, 3.0940, 3.0321],\n",
            "        [3.0378, 2.8853, 3.4975, 3.1370, 2.8796, 3.4106],\n",
            "        [3.0671, 3.2081, 3.4215, 3.2577, 2.9367, 3.1894],\n",
            "        [2.7798, 2.8146, 2.9141, 2.8853, 2.7204, 2.8437],\n",
            "        [3.5306, 3.5444, 3.5268, 3.5477, 3.1506, 3.3132],\n",
            "        [3.2915, 3.2259, 3.3470, 3.3705, 3.0689, 3.1792],\n",
            "        [3.2660, 3.0003, 3.1682, 3.0686, 2.6591, 3.1289],\n",
            "        [3.3853, 3.2734, 3.4439, 3.2232, 2.9015, 3.2304],\n",
            "        [3.3125, 3.1419, 3.4217, 3.4685, 3.1342, 3.3148],\n",
            "        [3.5075, 3.2606, 3.2992, 3.3550, 3.4327, 3.4330],\n",
            "        [3.1695, 2.9988, 3.1691, 3.3256, 3.1178, 2.9989],\n",
            "        [3.3871, 3.3838, 3.5013, 3.4661, 3.1401, 3.4366],\n",
            "        [3.4034, 3.0108, 3.2226, 3.3785, 2.7969, 3.2538],\n",
            "        [3.2241, 3.2356, 3.3703, 3.4429, 3.0789, 3.0595],\n",
            "        [3.4424, 3.2492, 3.6092, 3.5410, 3.3423, 3.3310],\n",
            "        [3.1763, 3.0203, 3.1934, 3.1001, 2.9550, 3.0398],\n",
            "        [3.2603, 3.0815, 3.1694, 3.3037, 3.0604, 3.1121],\n",
            "        [2.8713, 2.8784, 2.7939, 2.7953, 2.8838, 2.5915],\n",
            "        [3.3923, 3.6166, 3.5827, 3.4910, 3.2886, 3.4931],\n",
            "        [3.0631, 2.9863, 2.9594, 3.2672, 2.8651, 3.1000],\n",
            "        [3.1836, 3.1452, 3.2811, 3.2415, 2.9259, 3.1231],\n",
            "        [3.0793, 3.0078, 3.2095, 3.0762, 2.8113, 3.0518],\n",
            "        [3.3560, 3.2228, 3.4839, 3.6103, 3.2227, 3.2403],\n",
            "        [3.1427, 3.2739, 3.4422, 3.4652, 3.1842, 3.1207],\n",
            "        [3.2948, 3.2386, 3.3532, 3.4226, 3.1096, 3.1561],\n",
            "        [2.6127, 2.4204, 2.6728, 2.5984, 2.2458, 2.4919],\n",
            "        [2.8222, 2.7040, 2.9727, 2.9679, 2.8931, 2.8364],\n",
            "        [3.1028, 2.7767, 3.2578, 3.2856, 2.9758, 2.9654],\n",
            "        [3.3600, 3.3573, 3.3801, 3.4862, 3.3985, 3.3634],\n",
            "        [2.9528, 3.0636, 3.0981, 2.9253, 2.8339, 2.9615],\n",
            "        [3.0840, 2.6224, 2.8305, 2.9058, 2.7468, 2.8596],\n",
            "        [3.2303, 3.0556, 3.2607, 3.1348, 2.7865, 3.1616],\n",
            "        [2.6447, 2.8188, 3.0321, 3.1232, 3.1462, 2.8344],\n",
            "        [3.1592, 2.8908, 3.4337, 3.3533, 3.0231, 3.0653],\n",
            "        [2.7673, 2.8827, 3.0661, 3.0607, 2.9757, 2.8902],\n",
            "        [3.5301, 3.2749, 3.5802, 3.3137, 3.0476, 3.1561],\n",
            "        [3.1005, 3.1424, 3.4819, 3.3970, 2.8768, 3.0047],\n",
            "        [2.7829, 3.0391, 3.0305, 3.0104, 2.9398, 3.0338],\n",
            "        [3.2721, 3.0697, 3.2353, 2.8794, 3.0938, 3.2015],\n",
            "        [3.2387, 3.1277, 3.4711, 3.3047, 3.0337, 3.1244],\n",
            "        [3.2028, 3.0137, 3.2745, 3.2092, 2.9382, 3.2400],\n",
            "        [3.0379, 2.7072, 3.1277, 2.9445, 2.7656, 2.8122],\n",
            "        [2.6689, 3.0357, 2.8179, 2.7312, 2.8100, 2.7251],\n",
            "        [2.9814, 2.9979, 3.2258, 3.2195, 2.9929, 3.1127],\n",
            "        [2.7642, 2.4640, 2.5626, 2.5700, 2.0404, 2.7157],\n",
            "        [3.3530, 3.2801, 3.5637, 3.2601, 3.0470, 3.2819],\n",
            "        [2.9830, 3.1343, 3.2127, 3.0749, 3.0639, 2.7575]],\n",
            "       grad_fn=<ToCopyBackward0>)\n",
            "tensor([[2.0000, 2.0000, 3.0000, 3.0000, 3.0000, 2.5000],\n",
            "        [3.5000, 3.5000, 3.5000, 4.0000, 3.0000, 4.0000],\n",
            "        [3.0000, 3.5000, 3.0000, 3.0000, 3.0000, 3.5000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.5000, 2.5000, 2.5000],\n",
            "        [2.0000, 2.5000, 3.0000, 2.5000, 3.0000, 3.0000],\n",
            "        [3.0000, 2.5000, 2.0000, 2.5000, 2.5000, 3.0000],\n",
            "        [2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.5000, 3.5000, 3.5000],\n",
            "        [2.5000, 3.0000, 2.5000, 2.5000, 2.5000, 2.5000],\n",
            "        [3.0000, 2.5000, 3.0000, 2.5000, 2.0000, 3.0000],\n",
            "        [2.5000, 2.5000, 2.5000, 3.0000, 3.0000, 2.5000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.5000, 3.5000, 3.0000],\n",
            "        [3.0000, 2.5000, 2.0000, 2.0000, 2.5000, 3.0000],\n",
            "        [4.0000, 3.0000, 4.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [2.5000, 2.5000, 3.5000, 3.0000, 3.0000, 3.0000],\n",
            "        [3.0000, 2.0000, 3.0000, 3.0000, 2.0000, 2.5000],\n",
            "        [3.5000, 4.5000, 4.0000, 4.0000, 4.5000, 4.0000],\n",
            "        [3.5000, 3.5000, 3.0000, 3.5000, 4.0000, 4.0000],\n",
            "        [2.5000, 2.0000, 2.5000, 2.0000, 2.5000, 2.0000],\n",
            "        [4.0000, 4.5000, 4.5000, 5.0000, 4.0000, 4.5000],\n",
            "        [2.5000, 2.5000, 2.5000, 3.0000, 2.5000, 3.0000],\n",
            "        [3.5000, 3.0000, 3.5000, 2.5000, 3.0000, 3.0000],\n",
            "        [2.0000, 2.5000, 2.5000, 2.0000, 2.5000, 2.0000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.5000, 4.0000, 3.0000],\n",
            "        [2.5000, 2.0000, 2.5000, 2.5000, 2.5000, 2.0000],\n",
            "        [3.5000, 2.5000, 4.0000, 3.0000, 3.0000, 4.0000],\n",
            "        [4.5000, 3.5000, 3.5000, 4.0000, 3.5000, 4.0000],\n",
            "        [4.0000, 4.0000, 3.0000, 3.5000, 4.0000, 3.5000],\n",
            "        [2.5000, 2.5000, 3.5000, 3.5000, 3.0000, 3.0000],\n",
            "        [2.0000, 2.5000, 2.0000, 2.0000, 2.5000, 2.5000],\n",
            "        [4.0000, 3.5000, 3.0000, 3.0000, 3.5000, 3.5000],\n",
            "        [3.0000, 3.5000, 3.5000, 4.0000, 4.5000, 4.0000],\n",
            "        [3.0000, 2.5000, 3.0000, 2.5000, 2.5000, 3.0000],\n",
            "        [3.5000, 3.5000, 3.0000, 3.0000, 3.5000, 3.5000],\n",
            "        [3.0000, 3.0000, 2.5000, 2.5000, 3.0000, 3.0000],\n",
            "        [3.0000, 3.0000, 2.5000, 3.0000, 3.0000, 3.5000],\n",
            "        [4.0000, 3.5000, 4.0000, 3.5000, 3.5000, 4.0000],\n",
            "        [2.5000, 2.0000, 3.0000, 2.5000, 2.5000, 2.0000],\n",
            "        [3.5000, 3.5000, 3.0000, 3.5000, 3.5000, 2.5000],\n",
            "        [3.0000, 2.0000, 3.0000, 3.0000, 2.5000, 2.5000],\n",
            "        [4.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [3.5000, 2.5000, 3.5000, 3.0000, 3.5000, 2.5000],\n",
            "        [3.0000, 3.0000, 3.0000, 4.0000, 3.5000, 3.5000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.0000, 2.5000, 3.5000],\n",
            "        [2.5000, 3.0000, 3.0000, 3.0000, 2.5000, 3.0000],\n",
            "        [2.0000, 2.0000, 2.5000, 2.0000, 3.0000, 2.0000],\n",
            "        [3.0000, 2.5000, 3.5000, 3.5000, 3.0000, 3.0000],\n",
            "        [2.5000, 2.5000, 3.0000, 2.0000, 3.0000, 3.5000],\n",
            "        [3.0000, 2.0000, 2.5000, 2.5000, 2.5000, 2.0000],\n",
            "        [3.0000, 3.0000, 4.0000, 3.0000, 3.5000, 3.0000],\n",
            "        [4.0000, 3.5000, 4.0000, 3.5000, 4.0000, 3.5000],\n",
            "        [2.0000, 2.5000, 3.0000, 3.0000, 2.0000, 2.5000],\n",
            "        [4.0000, 3.5000, 4.0000, 4.5000, 4.0000, 3.0000],\n",
            "        [4.0000, 3.0000, 3.0000, 3.0000, 3.5000, 3.5000],\n",
            "        [3.5000, 3.5000, 4.0000, 4.0000, 3.5000, 4.0000],\n",
            "        [2.5000, 3.0000, 3.0000, 3.5000, 4.0000, 3.0000],\n",
            "        [3.5000, 3.0000, 3.0000, 3.5000, 3.5000, 3.5000],\n",
            "        [3.0000, 2.5000, 3.0000, 2.5000, 2.5000, 2.5000],\n",
            "        [4.5000, 3.0000, 3.5000, 3.5000, 3.5000, 4.0000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.5000, 3.5000, 4.0000],\n",
            "        [2.5000, 2.5000, 3.0000, 2.5000, 2.0000, 2.5000],\n",
            "        [3.5000, 2.5000, 3.5000, 3.0000, 2.5000, 3.5000],\n",
            "        [2.0000, 3.0000, 3.0000, 3.5000, 3.5000, 3.5000],\n",
            "        [2.5000, 2.0000, 2.5000, 2.0000, 2.0000, 3.0000]]) tensor([[3.4488, 3.1553, 3.6970, 3.6987, 3.1486, 3.4787],\n",
            "        [3.3661, 3.2298, 3.5631, 3.4397, 3.3070, 3.1901],\n",
            "        [2.6225, 2.6675, 2.8537, 2.8277, 2.7055, 2.8402],\n",
            "        [3.2855, 3.1644, 3.4504, 3.2402, 3.1879, 3.1535],\n",
            "        [2.7452, 2.8662, 2.9591, 2.8641, 2.7754, 2.7574],\n",
            "        [3.2127, 3.0189, 3.0776, 3.2910, 2.9277, 2.9772],\n",
            "        [2.8092, 2.7676, 3.3396, 3.2607, 2.6841, 3.0074],\n",
            "        [3.2379, 3.3940, 3.4059, 3.2802, 3.2351, 3.5180],\n",
            "        [3.3503, 3.2226, 3.4653, 3.4008, 3.2423, 3.1480],\n",
            "        [3.0584, 2.7767, 3.0928, 2.7966, 2.9126, 2.9513],\n",
            "        [2.5553, 2.3802, 2.6865, 2.7275, 2.6478, 2.5763],\n",
            "        [3.3780, 3.1735, 3.2630, 3.1320, 3.1661, 2.8110],\n",
            "        [3.4911, 3.1166, 3.4975, 3.4926, 3.2656, 3.3351],\n",
            "        [2.9711, 3.2393, 3.2982, 3.3245, 3.2733, 3.3322],\n",
            "        [3.1943, 3.0189, 3.4431, 3.2350, 2.8686, 3.1704],\n",
            "        [3.2044, 2.9606, 3.4097, 3.2393, 2.9932, 3.2244],\n",
            "        [3.4693, 3.3797, 3.3043, 3.3939, 3.0963, 3.3867],\n",
            "        [3.1513, 3.2941, 3.1358, 3.2159, 3.2864, 3.1500],\n",
            "        [2.8589, 2.9501, 3.0949, 2.8529, 2.8048, 2.9544],\n",
            "        [3.3310, 3.2767, 3.7259, 3.4703, 3.3113, 3.2426],\n",
            "        [2.7535, 2.7827, 2.9185, 2.6680, 2.6722, 2.6230],\n",
            "        [2.8801, 2.8251, 2.9885, 2.9780, 3.0370, 2.7847],\n",
            "        [2.6928, 2.6651, 2.8002, 2.7260, 2.5562, 2.5139],\n",
            "        [2.9461, 3.1726, 2.9059, 3.0641, 3.0200, 3.0327],\n",
            "        [2.8013, 2.9480, 3.0170, 2.8445, 3.0135, 2.8074],\n",
            "        [2.6174, 2.8049, 2.9379, 2.9982, 2.7076, 2.9034],\n",
            "        [3.2000, 3.2398, 3.6337, 3.5653, 3.1118, 3.3860],\n",
            "        [2.9402, 2.8509, 3.2079, 2.9157, 3.2677, 2.6839],\n",
            "        [3.3156, 3.3572, 3.2255, 3.2175, 3.4009, 3.1683],\n",
            "        [2.7350, 2.4582, 2.5953, 2.6146, 2.2027, 2.4282],\n",
            "        [3.6748, 3.6205, 3.6018, 3.4802, 3.5620, 3.6454],\n",
            "        [3.2200, 3.2956, 3.5833, 3.5387, 3.3607, 3.4579],\n",
            "        [3.3711, 3.2166, 3.5746, 3.2618, 3.1046, 3.3417],\n",
            "        [3.1960, 3.1814, 3.2915, 3.3121, 2.9659, 3.3347],\n",
            "        [2.6656, 2.9317, 2.9696, 2.9759, 2.7644, 3.0528],\n",
            "        [2.4431, 2.3286, 2.6931, 2.4859, 2.5918, 2.3367],\n",
            "        [3.4539, 3.2076, 3.6194, 3.7058, 3.3767, 3.5025],\n",
            "        [2.8774, 2.8240, 3.1316, 2.9497, 2.6709, 3.1029],\n",
            "        [3.6106, 3.2449, 3.4571, 3.5035, 3.1872, 3.3951],\n",
            "        [2.6849, 2.7896, 2.8675, 2.6326, 2.7198, 2.9258],\n",
            "        [3.2256, 3.0056, 3.2320, 3.1979, 2.9245, 3.0850],\n",
            "        [2.7265, 2.9093, 2.7101, 2.9380, 3.1587, 2.8695],\n",
            "        [2.7526, 2.7579, 2.9413, 2.6840, 2.8133, 2.7544],\n",
            "        [3.2285, 3.0188, 3.3182, 3.1671, 3.0617, 3.2176],\n",
            "        [2.7459, 2.8866, 3.0231, 3.0746, 3.0399, 2.9607],\n",
            "        [2.4973, 2.6544, 2.7837, 2.4019, 2.7817, 2.5117],\n",
            "        [3.0060, 3.0297, 3.0488, 2.9309, 2.6002, 3.0480],\n",
            "        [2.5654, 2.5396, 2.7261, 2.6092, 2.7957, 2.7950],\n",
            "        [2.9942, 3.1824, 2.9793, 3.1528, 2.8488, 3.0498],\n",
            "        [3.3820, 3.1330, 3.0520, 3.0747, 2.9416, 3.1496],\n",
            "        [2.9868, 2.9932, 3.1853, 3.2291, 3.0916, 3.1194],\n",
            "        [3.1264, 3.1592, 3.3598, 3.3958, 3.2522, 3.2269],\n",
            "        [3.3138, 3.1813, 3.5364, 3.3989, 3.1026, 3.4363],\n",
            "        [3.2859, 3.0147, 3.1585, 3.1665, 2.9229, 3.0839],\n",
            "        [3.1440, 3.0850, 3.3511, 3.2438, 3.0073, 3.1877],\n",
            "        [3.1160, 2.9933, 3.0277, 3.0491, 2.6199, 3.1239],\n",
            "        [2.7849, 2.7808, 2.9864, 2.9100, 2.6527, 2.9346],\n",
            "        [2.7960, 2.9044, 2.9254, 2.9842, 2.5558, 2.9982],\n",
            "        [2.7484, 2.7364, 3.1069, 2.9121, 2.7891, 2.7986],\n",
            "        [3.2162, 3.1420, 3.3027, 3.1988, 2.9653, 3.1618],\n",
            "        [2.5804, 2.7246, 2.8413, 2.8608, 2.6521, 2.7103],\n",
            "        [3.5003, 3.2312, 3.4310, 3.2511, 3.0814, 3.3099],\n",
            "        [3.1811, 2.9070, 3.2236, 2.8115, 3.0903, 2.8241],\n",
            "        [3.0161, 3.0731, 3.3056, 3.1545, 2.7762, 3.0817]],\n",
            "       grad_fn=<ToCopyBackward0>)\n",
            "tensor([[3.5000, 3.5000, 3.5000, 3.5000, 3.0000, 3.0000],\n",
            "        [4.0000, 3.5000, 4.0000, 3.5000, 3.5000, 3.5000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.0000, 3.0000, 3.5000],\n",
            "        [3.0000, 2.5000, 3.0000, 2.5000, 2.0000, 2.0000],\n",
            "        [4.0000, 3.5000, 4.0000, 4.0000, 3.5000, 3.5000],\n",
            "        [2.5000, 3.0000, 3.0000, 3.0000, 3.0000, 2.5000],\n",
            "        [3.5000, 3.0000, 3.5000, 2.5000, 3.0000, 3.0000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.5000, 2.5000, 2.5000],\n",
            "        [3.5000, 3.0000, 3.0000, 3.5000, 3.0000, 3.0000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.5000, 3.0000, 3.5000],\n",
            "        [3.0000, 2.5000, 3.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.5000],\n",
            "        [3.5000, 3.5000, 3.0000, 3.0000, 3.0000, 2.5000],\n",
            "        [2.5000, 2.5000, 2.5000, 2.5000, 2.5000, 2.5000],\n",
            "        [2.0000, 2.5000, 2.5000, 2.5000, 2.0000, 2.5000],\n",
            "        [3.0000, 2.5000, 3.0000, 2.5000, 2.0000, 2.5000],\n",
            "        [2.0000, 2.0000, 3.0000, 2.5000, 2.5000, 2.0000],\n",
            "        [3.5000, 3.5000, 4.5000, 4.5000, 4.0000, 4.0000],\n",
            "        [2.5000, 2.0000, 3.0000, 2.5000, 3.0000, 3.0000],\n",
            "        [1.5000, 2.0000, 1.5000, 1.5000, 2.0000, 1.5000],\n",
            "        [4.0000, 3.0000, 3.5000, 4.0000, 4.0000, 3.0000],\n",
            "        [3.0000, 2.5000, 3.0000, 3.0000, 2.0000, 3.5000],\n",
            "        [3.5000, 3.0000, 3.5000, 2.5000, 3.0000, 3.5000],\n",
            "        [3.0000, 2.5000, 2.5000, 3.0000, 2.5000, 3.0000],\n",
            "        [2.5000, 2.0000, 3.0000, 2.0000, 2.5000, 2.5000],\n",
            "        [4.0000, 3.5000, 3.5000, 3.5000, 3.0000, 3.0000],\n",
            "        [2.5000, 2.0000, 2.5000, 2.5000, 2.0000, 2.0000],\n",
            "        [1.5000, 2.0000, 2.5000, 2.0000, 2.0000, 1.5000],\n",
            "        [3.0000, 2.5000, 3.5000, 2.5000, 2.5000, 2.5000],\n",
            "        [4.5000, 4.5000, 5.0000, 5.0000, 5.0000, 5.0000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],\n",
            "        [4.0000, 3.0000, 4.0000, 3.5000, 3.5000, 3.0000],\n",
            "        [4.0000, 3.5000, 3.0000, 3.0000, 3.0000, 4.0000],\n",
            "        [4.0000, 4.0000, 3.0000, 4.0000, 4.5000, 4.0000],\n",
            "        [3.5000, 3.0000, 4.0000, 3.0000, 3.5000, 3.0000],\n",
            "        [3.0000, 2.5000, 3.5000, 3.0000, 2.5000, 3.5000],\n",
            "        [2.5000, 2.5000, 3.0000, 3.5000, 3.5000, 3.0000],\n",
            "        [3.5000, 3.0000, 3.0000, 3.5000, 3.0000, 3.5000],\n",
            "        [3.5000, 3.0000, 3.0000, 3.0000, 2.5000, 4.0000],\n",
            "        [3.0000, 3.5000, 2.5000, 3.0000, 4.0000, 3.0000],\n",
            "        [3.0000, 3.0000, 3.5000, 3.5000, 2.5000, 3.5000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.5000, 3.5000, 2.5000],\n",
            "        [2.5000, 2.5000, 3.0000, 3.0000, 2.5000, 2.5000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.5000, 4.0000, 4.0000],\n",
            "        [4.0000, 3.5000, 4.0000, 3.5000, 4.0000, 3.5000],\n",
            "        [4.5000, 5.0000, 5.0000, 5.0000, 4.5000, 4.5000],\n",
            "        [2.5000, 2.5000, 3.0000, 2.5000, 3.0000, 3.0000],\n",
            "        [2.5000, 2.5000, 3.0000, 2.5000, 2.5000, 2.0000],\n",
            "        [4.0000, 3.0000, 3.5000, 4.0000, 3.0000, 4.0000],\n",
            "        [4.0000, 4.0000, 3.5000, 4.0000, 4.0000, 4.0000],\n",
            "        [2.5000, 3.5000, 3.5000, 3.5000, 3.0000, 3.0000],\n",
            "        [3.0000, 2.0000, 3.0000, 2.0000, 2.5000, 2.5000],\n",
            "        [2.5000, 2.5000, 3.0000, 2.5000, 2.5000, 2.5000],\n",
            "        [3.0000, 2.5000, 3.0000, 2.5000, 2.0000, 3.0000],\n",
            "        [3.0000, 3.5000, 3.5000, 3.5000, 3.0000, 3.5000],\n",
            "        [3.0000, 3.0000, 4.0000, 3.0000, 3.5000, 3.0000],\n",
            "        [2.0000, 2.5000, 2.5000, 2.5000, 2.5000, 2.0000],\n",
            "        [2.5000, 2.0000, 2.5000, 2.0000, 2.0000, 2.0000],\n",
            "        [2.5000, 3.0000, 2.5000, 2.5000, 2.0000, 2.0000],\n",
            "        [3.0000, 2.5000, 2.5000, 2.5000, 2.5000, 3.0000],\n",
            "        [2.0000, 2.5000, 3.0000, 2.5000, 2.5000, 3.0000],\n",
            "        [4.0000, 4.5000, 4.0000, 4.0000, 4.0000, 4.5000],\n",
            "        [2.5000, 2.5000, 3.0000, 2.5000, 2.5000, 2.5000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.0000, 3.0000, 3.5000]]) tensor([[3.1584, 3.4072, 3.7430, 3.6435, 3.0113, 3.3514],\n",
            "        [3.2817, 3.0894, 3.0645, 3.3917, 2.8708, 3.1652],\n",
            "        [3.4274, 3.1606, 3.5187, 3.5128, 3.3512, 3.2161],\n",
            "        [3.1262, 3.1209, 3.5676, 3.4667, 2.9993, 3.1824],\n",
            "        [3.3128, 3.2053, 3.6019, 3.4107, 3.0569, 3.1918],\n",
            "        [2.9280, 2.8171, 3.0760, 2.9634, 2.8907, 2.9650],\n",
            "        [3.0975, 3.0092, 2.9513, 2.9534, 2.9650, 3.0309],\n",
            "        [3.1364, 3.0817, 3.4288, 3.2803, 2.9471, 3.2170],\n",
            "        [2.7113, 2.5941, 2.7930, 2.8134, 2.6329, 2.8044],\n",
            "        [3.2610, 3.2899, 3.2018, 3.1613, 2.9244, 3.1937],\n",
            "        [3.0163, 3.0438, 3.3944, 3.1774, 3.3229, 3.2030],\n",
            "        [2.1779, 2.1715, 2.4598, 2.1070, 2.3754, 2.3043],\n",
            "        [3.1986, 3.0796, 3.2506, 3.3704, 3.3294, 3.3453],\n",
            "        [2.8082, 2.4216, 3.1008, 2.8030, 2.8400, 2.8121],\n",
            "        [3.1957, 3.0114, 3.3497, 2.8924, 3.3871, 3.3218],\n",
            "        [2.7016, 2.9231, 2.7664, 2.9785, 2.8038, 2.8660],\n",
            "        [2.6125, 2.7816, 2.8190, 2.7671, 2.9617, 2.6498],\n",
            "        [3.2030, 3.2939, 3.5521, 3.2148, 3.1242, 3.3396],\n",
            "        [3.1216, 2.8983, 3.2536, 3.1969, 2.7391, 3.0646],\n",
            "        [2.6212, 2.7955, 2.9742, 2.7243, 2.9732, 2.9880],\n",
            "        [3.5534, 3.4652, 3.6315, 3.6337, 3.2829, 3.3461],\n",
            "        [3.7498, 3.6942, 3.7812, 3.7393, 3.7806, 3.7133],\n",
            "        [3.5377, 3.3458, 3.4766, 3.3799, 3.1776, 3.3766],\n",
            "        [3.3007, 3.1517, 3.3601, 3.4420, 2.9783, 3.2799],\n",
            "        [2.6681, 2.7009, 2.8384, 2.8687, 2.4174, 2.8889],\n",
            "        [3.1115, 3.1539, 2.9882, 3.0206, 2.7350, 3.2993],\n",
            "        [3.5360, 3.3454, 3.7553, 3.5924, 3.1312, 3.4330],\n",
            "        [2.5911, 2.7195, 2.8620, 2.7446, 2.8109, 2.6452],\n",
            "        [3.2299, 3.0268, 3.2122, 3.2549, 3.0813, 3.2165],\n",
            "        [3.5065, 3.5987, 3.9437, 3.8225, 3.3313, 3.6283],\n",
            "        [2.7986, 2.9519, 3.0312, 2.9704, 2.9872, 3.2286],\n",
            "        [3.3556, 3.4474, 3.4466, 3.3033, 3.0049, 3.2567],\n",
            "        [3.2284, 3.1444, 3.5826, 3.3472, 3.0261, 3.2321],\n",
            "        [3.4034, 3.4520, 3.4844, 3.3715, 3.1011, 3.4121],\n",
            "        [3.2343, 3.2480, 3.2961, 3.3468, 3.1446, 3.1297],\n",
            "        [3.1510, 3.0756, 2.9538, 3.2049, 2.9710, 2.9629],\n",
            "        [3.1016, 3.1186, 3.5413, 3.3713, 3.0367, 3.2212],\n",
            "        [3.1655, 3.2944, 3.0656, 3.2906, 2.9398, 3.1419],\n",
            "        [3.4600, 3.1550, 3.5446, 3.2665, 3.0129, 3.4257],\n",
            "        [2.6434, 2.6947, 2.8022, 2.7744, 2.3107, 2.7427],\n",
            "        [2.7881, 3.1123, 3.3390, 3.1608, 2.7745, 3.0487],\n",
            "        [3.2060, 2.8303, 3.0624, 3.0453, 2.6835, 2.8817],\n",
            "        [3.1816, 3.1210, 3.4330, 3.3639, 2.9850, 2.9464],\n",
            "        [3.2051, 2.8813, 3.2291, 3.2917, 3.2228, 3.3908],\n",
            "        [3.6547, 3.5239, 3.9823, 3.7285, 3.6152, 3.6692],\n",
            "        [3.4610, 3.1876, 3.4014, 3.3027, 3.0361, 2.9876],\n",
            "        [3.4302, 3.1716, 3.2193, 3.1833, 2.8849, 3.1893],\n",
            "        [2.5823, 2.5494, 2.8402, 2.5859, 2.7719, 2.4946],\n",
            "        [3.6242, 3.6159, 3.5171, 3.5405, 3.5842, 3.1977],\n",
            "        [3.4306, 3.3412, 3.4810, 3.1493, 3.1447, 3.2503],\n",
            "        [3.0990, 2.8620, 3.0877, 3.1742, 2.9962, 2.9459],\n",
            "        [3.3999, 3.1060, 3.8067, 3.5159, 3.1526, 3.2143],\n",
            "        [3.5011, 3.2585, 3.2905, 3.3277, 2.8836, 3.2393],\n",
            "        [3.2577, 3.0568, 3.3533, 3.1866, 2.9648, 3.5098],\n",
            "        [2.6229, 2.6113, 2.8087, 2.6765, 2.7560, 2.5513],\n",
            "        [3.5875, 3.1903, 3.4630, 3.2807, 3.1267, 3.3836],\n",
            "        [3.0921, 2.9140, 3.3174, 3.3952, 3.0053, 3.0509],\n",
            "        [2.9829, 3.1393, 3.1460, 2.9563, 2.9850, 3.0965],\n",
            "        [3.3626, 3.0829, 3.4209, 3.3946, 3.1927, 3.1158],\n",
            "        [3.3145, 3.0999, 3.2455, 3.1606, 3.0557, 3.0733],\n",
            "        [2.9978, 2.6328, 2.7972, 2.8689, 2.4783, 2.8731],\n",
            "        [3.3028, 3.1177, 3.3690, 3.3587, 3.0438, 3.2858],\n",
            "        [3.1162, 2.9102, 3.1279, 2.9952, 2.8290, 2.7154],\n",
            "        [3.3441, 3.2121, 3.4292, 3.3323, 3.0155, 3.4716]],\n",
            "       grad_fn=<ToCopyBackward0>)\n",
            "tensor([[3.5000, 3.5000, 3.5000, 4.0000, 4.0000, 4.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.5000, 3.5000, 3.0000],\n",
            "        [2.5000, 3.5000, 3.5000, 3.5000, 2.5000, 3.0000],\n",
            "        [3.0000, 2.5000, 2.5000, 2.0000, 2.5000, 2.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 2.0000],\n",
            "        [2.5000, 2.5000, 3.0000, 2.5000, 2.5000, 2.0000],\n",
            "        [4.0000, 4.5000, 4.5000, 4.0000, 4.0000, 4.0000],\n",
            "        [2.5000, 2.0000, 4.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [2.5000, 2.0000, 3.0000, 2.0000, 2.5000, 3.5000],\n",
            "        [2.5000, 3.0000, 3.0000, 3.0000, 2.0000, 2.5000],\n",
            "        [2.0000, 3.0000, 2.5000, 2.0000, 2.0000, 3.0000],\n",
            "        [3.0000, 3.5000, 3.0000, 3.0000, 3.5000, 4.0000],\n",
            "        [2.5000, 2.5000, 2.5000, 2.0000, 2.0000, 2.5000],\n",
            "        [2.5000, 3.0000, 3.0000, 2.0000, 2.0000, 2.5000],\n",
            "        [3.0000, 3.5000, 3.0000, 3.5000, 3.0000, 4.0000],\n",
            "        [3.0000, 3.0000, 3.5000, 3.0000, 3.0000, 3.0000],\n",
            "        [1.0000, 1.0000, 1.5000, 1.0000, 1.0000, 1.0000],\n",
            "        [3.5000, 3.5000, 3.0000, 2.5000, 2.5000, 3.0000],\n",
            "        [3.5000, 3.5000, 3.5000, 4.0000, 3.5000, 3.0000],\n",
            "        [2.0000, 2.0000, 2.5000, 3.0000, 2.5000, 2.5000],\n",
            "        [3.0000, 2.5000, 3.0000, 3.0000, 2.5000, 2.5000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.5000, 3.5000, 3.0000],\n",
            "        [3.5000, 3.5000, 3.0000, 3.0000, 3.0000, 3.5000],\n",
            "        [4.0000, 4.5000, 4.0000, 5.0000, 5.0000, 5.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.5000, 3.5000, 3.0000],\n",
            "        [2.0000, 2.0000, 3.0000, 2.5000, 2.5000, 2.0000],\n",
            "        [3.0000, 3.0000, 3.5000, 4.0000, 3.5000, 3.0000],\n",
            "        [2.5000, 3.0000, 3.0000, 4.0000, 3.5000, 3.5000],\n",
            "        [4.0000, 3.0000, 3.0000, 3.5000, 3.0000, 4.0000],\n",
            "        [1.0000, 1.5000, 1.5000, 2.0000, 1.5000, 1.0000],\n",
            "        [3.5000, 3.0000, 3.5000, 3.5000, 3.5000, 3.0000],\n",
            "        [4.5000, 4.0000, 4.0000, 4.0000, 4.5000, 4.0000],\n",
            "        [3.5000, 3.5000, 3.0000, 3.5000, 3.5000, 2.5000],\n",
            "        [2.5000, 2.5000, 2.5000, 2.0000, 2.0000, 2.0000],\n",
            "        [4.0000, 3.0000, 3.0000, 3.0000, 3.0000, 4.0000],\n",
            "        [2.5000, 3.5000, 3.5000, 3.0000, 3.5000, 3.0000],\n",
            "        [2.0000, 2.5000, 3.0000, 3.0000, 3.0000, 2.0000],\n",
            "        [2.0000, 3.0000, 3.0000, 3.0000, 3.0000, 4.0000],\n",
            "        [2.0000, 2.5000, 3.0000, 2.5000, 3.0000, 2.5000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.0000],\n",
            "        [2.5000, 2.5000, 2.0000, 2.5000, 2.5000, 2.0000],\n",
            "        [2.5000, 3.0000, 2.5000, 3.0000, 2.5000, 2.0000],\n",
            "        [3.0000, 2.5000, 2.5000, 2.5000, 2.0000, 3.0000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 3.5000, 3.0000],\n",
            "        [2.0000, 3.0000, 3.0000, 3.0000, 2.5000, 3.0000],\n",
            "        [2.0000, 2.0000, 3.0000, 2.0000, 2.5000, 2.5000],\n",
            "        [3.0000, 3.5000, 3.0000, 3.0000, 3.0000, 2.5000],\n",
            "        [3.5000, 2.5000, 3.5000, 3.0000, 3.0000, 3.5000],\n",
            "        [3.0000, 2.5000, 3.0000, 2.5000, 2.0000, 3.0000],\n",
            "        [4.5000, 4.0000, 3.5000, 4.0000, 3.0000, 4.0000],\n",
            "        [2.5000, 2.5000, 2.0000, 2.0000, 2.0000, 3.0000],\n",
            "        [2.0000, 2.5000, 2.5000, 2.5000, 2.0000, 2.5000],\n",
            "        [3.5000, 3.5000, 3.0000, 3.5000, 3.5000, 4.0000],\n",
            "        [3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000],\n",
            "        [3.0000, 3.5000, 4.0000, 4.0000, 3.5000, 3.5000],\n",
            "        [3.0000, 3.0000, 3.0000, 3.0000, 2.5000, 2.5000],\n",
            "        [2.5000, 2.5000, 2.5000, 2.0000, 2.0000, 2.0000],\n",
            "        [2.5000, 3.0000, 3.0000, 2.5000, 2.5000, 3.0000],\n",
            "        [3.0000, 3.0000, 3.5000, 3.0000, 2.5000, 2.5000],\n",
            "        [3.5000, 3.0000, 3.0000, 3.5000, 3.5000, 2.5000],\n",
            "        [2.5000, 3.0000, 2.5000, 2.5000, 3.0000, 2.5000],\n",
            "        [3.0000, 3.5000, 3.0000, 3.0000, 3.0000, 3.0000],\n",
            "        [5.0000, 4.0000, 4.0000, 4.5000, 4.0000, 4.0000],\n",
            "        [3.5000, 3.5000, 3.0000, 3.5000, 3.0000, 3.0000]]) tensor([[2.7960, 3.1871, 3.2235, 2.9799, 3.0238, 2.9624],\n",
            "        [2.7292, 2.4425, 2.7941, 2.6106, 2.5552, 2.4255],\n",
            "        [3.1450, 3.1285, 3.4372, 3.1659, 2.9544, 3.0926],\n",
            "        [2.9458, 2.8825, 3.2165, 2.9837, 2.7556, 2.8768],\n",
            "        [2.5450, 2.6364, 2.7538, 2.9660, 2.9840, 2.8924],\n",
            "        [2.7336, 2.5683, 2.8359, 2.9394, 2.7044, 2.6146],\n",
            "        [3.2651, 3.2456, 3.3480, 3.2525, 2.9229, 3.1831],\n",
            "        [3.3894, 3.1233, 3.4796, 3.5923, 3.3193, 3.1183],\n",
            "        [2.5008, 2.8246, 2.7873, 2.7587, 2.3334, 2.7138],\n",
            "        [2.4461, 2.5540, 2.6047, 2.6067, 2.3620, 2.3361],\n",
            "        [2.6899, 2.8326, 2.9180, 2.8586, 2.5862, 2.9507],\n",
            "        [3.2611, 3.2684, 3.3659, 3.3562, 3.2807, 3.2716],\n",
            "        [3.0582, 2.8673, 3.3433, 3.1284, 2.8934, 3.0734],\n",
            "        [3.5204, 3.1347, 3.5569, 3.4919, 3.1554, 3.2643],\n",
            "        [3.2135, 3.0877, 3.5427, 3.3000, 3.2021, 3.1099],\n",
            "        [3.0736, 3.0374, 3.4023, 3.3351, 3.0839, 3.0162],\n",
            "        [3.3833, 3.4541, 3.5638, 3.9876, 3.3187, 3.2912],\n",
            "        [3.0491, 3.0575, 3.3095, 3.3718, 2.9141, 3.0237],\n",
            "        [3.6205, 3.2842, 3.5440, 3.4797, 3.2990, 3.4842],\n",
            "        [2.8145, 2.4412, 2.8385, 2.8665, 2.7166, 2.6195],\n",
            "        [2.6990, 2.6198, 2.9517, 3.0061, 2.3612, 2.8913],\n",
            "        [3.0422, 2.7352, 3.1358, 3.2405, 2.7802, 3.0233],\n",
            "        [2.7233, 2.7083, 2.9752, 2.8057, 2.9743, 2.8834],\n",
            "        [3.2646, 3.2714, 3.4528, 3.4064, 3.1914, 3.5251],\n",
            "        [2.9767, 2.8422, 2.9788, 3.0935, 2.9121, 3.0230],\n",
            "        [3.4909, 3.1615, 3.4517, 3.2794, 3.1245, 3.1495],\n",
            "        [3.2209, 3.2446, 3.4946, 3.3649, 3.1595, 3.3459],\n",
            "        [3.0724, 2.9173, 3.2736, 3.2131, 2.9152, 3.0204],\n",
            "        [3.1195, 3.0570, 3.2688, 3.2668, 3.0574, 3.0602],\n",
            "        [3.0403, 3.0059, 3.4080, 3.3470, 2.4584, 3.0223],\n",
            "        [3.4144, 3.1258, 3.4453, 3.3912, 3.1978, 3.0483],\n",
            "        [3.3851, 3.1928, 3.4944, 3.3392, 3.1818, 3.4890],\n",
            "        [3.2574, 3.1128, 3.0576, 3.0011, 3.0563, 2.9185],\n",
            "        [3.1754, 3.0951, 3.4105, 3.1903, 2.9305, 3.0321],\n",
            "        [3.0995, 3.1318, 3.1937, 3.2165, 2.9271, 3.1617],\n",
            "        [3.0082, 3.1663, 3.2233, 3.4196, 3.4017, 3.1760],\n",
            "        [2.8369, 2.9483, 3.0908, 3.0370, 2.6767, 2.8479],\n",
            "        [2.4144, 2.3464, 2.6034, 2.2099, 2.4704, 2.4666],\n",
            "        [3.2930, 3.1807, 3.2655, 3.3278, 3.3980, 3.2289],\n",
            "        [3.4310, 3.3126, 3.4214, 3.3103, 3.1579, 3.5594],\n",
            "        [2.7073, 2.6343, 2.8691, 2.7837, 2.7552, 2.8448],\n",
            "        [2.8165, 2.7867, 2.9910, 2.9443, 2.7322, 3.0053],\n",
            "        [2.8394, 2.8000, 2.8752, 2.8615, 2.9643, 2.6872],\n",
            "        [2.4559, 2.4141, 2.6475, 2.5819, 2.5386, 2.4914],\n",
            "        [3.1246, 2.6964, 3.0167, 3.0897, 2.6585, 2.8882],\n",
            "        [3.4454, 3.2365, 3.4170, 3.2732, 3.0015, 3.4186],\n",
            "        [3.0520, 2.8721, 3.1491, 3.0391, 3.1852, 2.9208],\n",
            "        [3.3138, 3.1148, 3.3447, 3.2553, 3.1452, 3.1024],\n",
            "        [2.7689, 2.4855, 2.9501, 2.7315, 2.7308, 2.7262],\n",
            "        [3.6762, 3.5095, 3.4432, 3.4601, 3.3342, 3.3127],\n",
            "        [2.8029, 3.0262, 3.0837, 2.8117, 2.9640, 3.0161],\n",
            "        [2.8286, 2.8194, 2.9720, 3.2414, 2.8582, 2.8768],\n",
            "        [2.6989, 2.7303, 2.7539, 2.7179, 2.7782, 2.5851],\n",
            "        [3.3807, 3.2998, 3.2296, 3.4282, 3.1550, 3.3111],\n",
            "        [3.5703, 3.5347, 3.6958, 3.4270, 3.5961, 3.3372],\n",
            "        [2.8859, 2.9394, 3.0201, 2.9990, 3.0181, 3.0543],\n",
            "        [2.8774, 2.8992, 3.1140, 3.0409, 2.6154, 3.0342],\n",
            "        [2.5125, 2.3260, 2.8593, 2.6252, 2.6191, 2.5848],\n",
            "        [3.0700, 3.0047, 3.1473, 3.1399, 2.7684, 3.0436],\n",
            "        [3.1338, 3.0242, 3.2739, 3.3590, 3.2952, 3.0416],\n",
            "        [2.5991, 2.5589, 2.7604, 2.5296, 2.6349, 2.4883],\n",
            "        [3.3825, 3.1779, 3.2659, 3.2577, 3.0984, 3.1836],\n",
            "        [3.4210, 3.2232, 3.6754, 3.5032, 3.0732, 3.1522],\n",
            "        [3.5501, 3.2381, 3.3151, 3.4528, 3.0838, 3.3351]],\n",
            "       grad_fn=<ToCopyBackward0>)\n",
            "tensor([[3.1214, 3.2791, 3.5201, 3.2892, 2.9126, 3.2154],\n",
            "        [3.0841, 3.0066, 3.0250, 3.0299, 2.8272, 2.7366],\n",
            "        [3.0531, 3.1099, 3.2727, 3.1720, 2.7124, 3.1099]],\n",
            "       grad_fn=<ToCopyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALIzLcf0uPN9",
        "outputId": "5254ff0a-fc0c-4ede-b37b-209e7a493b14"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.3236, 3.2663, 3.4230, 3.3187, 3.0493, 3.0218],\n",
              "        [3.1544, 2.8722, 3.1729, 3.0977, 2.9937, 2.6792],\n",
              "        [3.1798, 3.0393, 3.2963, 3.2644, 2.9128, 3.0848]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s9TBXLs-y0Fw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}